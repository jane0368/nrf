dataset: 29514, train_set: 27000, val_set: 2514
(train)===> Epoch[1/1000]): Loss: 0.24807839718538902 Acc: 25147
(validation)===> Epoch[1/1000]): Acc: 0.9314903846153846
(train)===> Epoch[2/1000]): Loss: 0.2422551287608022 Acc: 25165
(train)===> Epoch[3/1000]): Loss: 0.23694404433182742 Acc: 25158
(train)===> Epoch[4/1000]): Loss: 0.2337516463779782 Acc: 25168
(train)===> Epoch[5/1000]): Loss: 0.23097219421680928 Acc: 25167
(train)===> Epoch[6/1000]): Loss: 0.22891457831916226 Acc: 25167
(train)===> Epoch[7/1000]): Loss: 0.22563630464595183 Acc: 25166
(train)===> Epoch[8/1000]): Loss: 0.22196453905303795 Acc: 25179
(train)===> Epoch[9/1000]): Loss: 0.2190900089356366 Acc: 25192
(train)===> Epoch[10/1000]): Loss: 0.21812608790298552 Acc: 25177
(train)===> Epoch[11/1000]): Loss: 0.21412284743934523 Acc: 25196
(validation)===> Epoch[11/1000]): Acc: 0.9326923076923077
(train)===> Epoch[12/1000]): Loss: 0.20983263402469363 Acc: 25209
(train)===> Epoch[13/1000]): Loss: 0.20798443509995798 Acc: 25223
(train)===> Epoch[14/1000]): Loss: 0.20329534992434076 Acc: 25236
(train)===> Epoch[15/1000]): Loss: 0.2022108351745401 Acc: 25217
(train)===> Epoch[16/1000]): Loss: 0.19841734748200962 Acc: 25268
(train)===> Epoch[17/1000]): Loss: 0.1940696740748623 Acc: 25284
(train)===> Epoch[18/1000]): Loss: 0.19202483263123338 Acc: 25279
(train)===> Epoch[19/1000]): Loss: 0.18829296215165264 Acc: 25291
(train)===> Epoch[20/1000]): Loss: 0.18426778157752624 Acc: 25327
(train)===> Epoch[21/1000]): Loss: 0.18328029577423427 Acc: 25322
(validation)===> Epoch[21/1000]): Acc: 0.9342948717948718
(train)===> Epoch[22/1000]): Loss: 0.18038335043467982 Acc: 25345
(train)===> Epoch[23/1000]): Loss: 0.17764489586307997 Acc: 25347
(train)===> Epoch[24/1000]): Loss: 0.17597602235237392 Acc: 25377
(train)===> Epoch[25/1000]): Loss: 0.1744854939822772 Acc: 25353
(train)===> Epoch[26/1000]): Loss: 0.17379953630817188 Acc: 25372
(train)===> Epoch[27/1000]): Loss: 0.16901228336214752 Acc: 25402
(train)===> Epoch[28/1000]): Loss: 0.16994122712211476 Acc: 25419
(train)===> Epoch[29/1000]): Loss: 0.16753676103653653 Acc: 25410
(train)===> Epoch[30/1000]): Loss: 0.16510615624363498 Acc: 25453
(train)===> Epoch[31/1000]): Loss: 0.16437676576388713 Acc: 25450
(validation)===> Epoch[31/1000]): Acc: 0.9447115384615384
(train)===> Epoch[32/1000]): Loss: 0.16295255310921938 Acc: 25451
(train)===> Epoch[33/1000]): Loss: 0.16275473945108268 Acc: 25477
(train)===> Epoch[34/1000]): Loss: 0.1572039915677912 Acc: 25530
(train)===> Epoch[35/1000]): Loss: 0.16082969077834028 Acc: 25463
(train)===> Epoch[36/1000]): Loss: 0.15665821982392786 Acc: 25487
(train)===> Epoch[37/1000]): Loss: 0.15803544778120202 Acc: 25515
(train)===> Epoch[38/1000]): Loss: 0.15675383085061995 Acc: 25512
(train)===> Epoch[39/1000]): Loss: 0.15676304610388567 Acc: 25502
(train)===> Epoch[40/1000]): Loss: 0.15209894599901808 Acc: 25580
(train)===> Epoch[41/1000]): Loss: 0.15254856282380588 Acc: 25537
(validation)===> Epoch[41/1000]): Acc: 0.9451121794871795
(train)===> Epoch[42/1000]): Loss: 0.15055315353135593 Acc: 25578
(train)===> Epoch[43/1000]): Loss: 0.15157797024308775 Acc: 25582
(train)===> Epoch[44/1000]): Loss: 0.15389019868949375 Acc: 25545
(train)===> Epoch[45/1000]): Loss: 0.14945917165973133 Acc: 25556
(train)===> Epoch[46/1000]): Loss: 0.15207188691492599 Acc: 25561
(train)===> Epoch[47/1000]): Loss: 0.15103917913135317 Acc: 25554
(train)===> Epoch[48/1000]): Loss: 0.1506888931993209 Acc: 25572
(train)===> Epoch[49/1000]): Loss: 0.14628009830829372 Acc: 25580
(train)===> Epoch[50/1000]): Loss: 0.14726279613135002 Acc: 25630
(train)===> Epoch[51/1000]): Loss: 0.14716173934964832 Acc: 25620
(validation)===> Epoch[51/1000]): Acc: 0.9451121794871795
(train)===> Epoch[52/1000]): Loss: 0.14646953703601126 Acc: 25596
(train)===> Epoch[53/1000]): Loss: 0.14318215418739716 Acc: 25650
(train)===> Epoch[54/1000]): Loss: 0.1427156949933451 Acc: 25636
(train)===> Epoch[55/1000]): Loss: 0.1451377534792004 Acc: 25631
(train)===> Epoch[56/1000]): Loss: 0.14376885334202344 Acc: 25612
(train)===> Epoch[57/1000]): Loss: 0.1427719125749805 Acc: 25650
(train)===> Epoch[58/1000]): Loss: 0.1434765428950626 Acc: 25659
(train)===> Epoch[59/1000]): Loss: 0.14217705414088488 Acc: 25676
(train)===> Epoch[60/1000]): Loss: 0.14186948747540007 Acc: 25627
(train)===> Epoch[61/1000]): Loss: 0.1380958570800101 Acc: 25697
(validation)===> Epoch[61/1000]): Acc: 0.9487179487179487
(train)===> Epoch[62/1000]): Loss: 0.14049958258938064 Acc: 25655
(train)===> Epoch[63/1000]): Loss: 0.13753031332249308 Acc: 25684
(train)===> Epoch[64/1000]): Loss: 0.1399961619985217 Acc: 25636
(train)===> Epoch[65/1000]): Loss: 0.1372516495120355 Acc: 25673
(train)===> Epoch[66/1000]): Loss: 0.13625896333621676 Acc: 25663
(train)===> Epoch[67/1000]): Loss: 0.1369381970958232 Acc: 25698
(train)===> Epoch[68/1000]): Loss: 0.13242153760107722 Acc: 25709
(train)===> Epoch[69/1000]): Loss: 0.1369161695250777 Acc: 25658
(train)===> Epoch[70/1000]): Loss: 0.1318044840289621 Acc: 25734
(train)===> Epoch[71/1000]): Loss: 0.13387651906974798 Acc: 25737
(validation)===> Epoch[71/1000]): Acc: 0.9475160256410257
(train)===> Epoch[72/1000]): Loss: 0.13266319897016982 Acc: 25712
(train)===> Epoch[73/1000]): Loss: 0.1325791192787418 Acc: 25709
(train)===> Epoch[74/1000]): Loss: 0.1356319151730266 Acc: 25719
(train)===> Epoch[75/1000]): Loss: 0.13502456808812266 Acc: 25709
(train)===> Epoch[76/1000]): Loss: 0.13261124380640768 Acc: 25708
(train)===> Epoch[77/1000]): Loss: 0.13027035511782362 Acc: 25745
(train)===> Epoch[78/1000]): Loss: 0.13401266784714694 Acc: 25701
(train)===> Epoch[79/1000]): Loss: 0.12995331423388098 Acc: 25730
(train)===> Epoch[80/1000]): Loss: 0.13371031669426411 Acc: 25722
(train)===> Epoch[81/1000]): Loss: 0.1314941408807266 Acc: 25738
(validation)===> Epoch[81/1000]): Acc: 0.9475160256410257
(train)===> Epoch[82/1000]): Loss: 0.1260823173328986 Acc: 25769
(train)===> Epoch[83/1000]): Loss: 0.1302913640782839 Acc: 25785
(train)===> Epoch[84/1000]): Loss: 0.13009714500673317 Acc: 25768
(train)===> Epoch[85/1000]): Loss: 0.12598503031491382 Acc: 25745
(train)===> Epoch[86/1000]): Loss: 0.12896694970314962 Acc: 25740
(train)===> Epoch[87/1000]): Loss: 0.1243166306460909 Acc: 25774
(train)===> Epoch[88/1000]): Loss: 0.12666166941425144 Acc: 25745
(train)===> Epoch[89/1000]): Loss: 0.12430721058592092 Acc: 25806
(train)===> Epoch[90/1000]): Loss: 0.12703250271142105 Acc: 25772
(train)===> Epoch[91/1000]): Loss: 0.12873878126030439 Acc: 25730
(validation)===> Epoch[91/1000]): Acc: 0.9487179487179487
(train)===> Epoch[92/1000]): Loss: 0.12192792642746557 Acc: 25802
(train)===> Epoch[93/1000]): Loss: 0.12405945980067487 Acc: 25818
(train)===> Epoch[94/1000]): Loss: 0.11998672272806504 Acc: 25805
(train)===> Epoch[95/1000]): Loss: 0.12485601668049207 Acc: 25771
(train)===> Epoch[96/1000]): Loss: 0.12186300993903659 Acc: 25815
(train)===> Epoch[97/1000]): Loss: 0.12130178938975945 Acc: 25842
(train)===> Epoch[98/1000]): Loss: 0.12488825465253857 Acc: 25792
(train)===> Epoch[99/1000]): Loss: 0.12326182273267428 Acc: 25773
(train)===> Epoch[100/1000]): Loss: 0.11949453867016237 Acc: 25823
(train)===> Epoch[101/1000]): Loss: 0.12050306606781182 Acc: 25828
(validation)===> Epoch[101/1000]): Acc: 0.9487179487179487
(train)===> Epoch[102/1000]): Loss: 0.12077674642647683 Acc: 25845
(train)===> Epoch[103/1000]): Loss: 0.11764154603125224 Acc: 25857
(train)===> Epoch[104/1000]): Loss: 0.12197007346376247 Acc: 25812
(train)===> Epoch[105/1000]): Loss: 0.11796149804374105 Acc: 25865
(train)===> Epoch[106/1000]): Loss: 0.11999101887707042 Acc: 25803
(train)===> Epoch[107/1000]): Loss: 0.11659433539169274 Acc: 25859
(train)===> Epoch[108/1000]): Loss: 0.11539907645956204 Acc: 25879
(train)===> Epoch[109/1000]): Loss: 0.11661193133586234 Acc: 25890
(train)===> Epoch[110/1000]): Loss: 0.11873378444931991 Acc: 25835
(train)===> Epoch[111/1000]): Loss: 0.11409058286465543 Acc: 25882
(validation)===> Epoch[111/1000]): Acc: 0.952323717948718
(train)===> Epoch[112/1000]): Loss: 0.11643018422652739 Acc: 25852
(train)===> Epoch[113/1000]): Loss: 0.11799841832077557 Acc: 25829
(train)===> Epoch[114/1000]): Loss: 0.11771388917789741 Acc: 25816
(train)===> Epoch[115/1000]): Loss: 0.1156977695145263 Acc: 25879
(train)===> Epoch[116/1000]): Loss: 0.11688246308093682 Acc: 25836
(train)===> Epoch[117/1000]): Loss: 0.113818648012439 Acc: 25848
(train)===> Epoch[118/1000]): Loss: 0.11419392664719921 Acc: 25899
(train)===> Epoch[119/1000]): Loss: 0.11390771081056146 Acc: 25892
(train)===> Epoch[120/1000]): Loss: 0.11145549085690268 Acc: 25919
(train)===> Epoch[121/1000]): Loss: 0.11636711412823957 Acc: 25830
(validation)===> Epoch[121/1000]): Acc: 0.953926282051282
(train)===> Epoch[122/1000]): Loss: 0.11176417629077431 Acc: 25916
(train)===> Epoch[123/1000]): Loss: 0.11344908287576151 Acc: 25881
(train)===> Epoch[124/1000]): Loss: 0.10839526736201836 Acc: 25918
(train)===> Epoch[125/1000]): Loss: 0.1130813347339418 Acc: 25861
(train)===> Epoch[126/1000]): Loss: 0.11065141456710476 Acc: 25908
(train)===> Epoch[127/1000]): Loss: 0.10915181536731842 Acc: 25912
(train)===> Epoch[128/1000]): Loss: 0.11126105010403313 Acc: 25908
(train)===> Epoch[129/1000]): Loss: 0.1078477742685771 Acc: 25925
(train)===> Epoch[130/1000]): Loss: 0.11037837497606848 Acc: 25906
(train)===> Epoch[131/1000]): Loss: 0.10989805745434304 Acc: 25900
(validation)===> Epoch[131/1000]): Acc: 0.9471153846153846
(train)===> Epoch[132/1000]): Loss: 0.11182294716071912 Acc: 25924
(train)===> Epoch[133/1000]): Loss: 0.1086924314021073 Acc: 25952
(train)===> Epoch[134/1000]): Loss: 0.11033930802925755 Acc: 25883
(train)===> Epoch[135/1000]): Loss: 0.10794895744468855 Acc: 25931
(train)===> Epoch[136/1000]): Loss: 0.10688556444492721 Acc: 25947
(train)===> Epoch[137/1000]): Loss: 0.10715269747758696 Acc: 25959
(train)===> Epoch[138/1000]): Loss: 0.10922787394241879 Acc: 25916
(train)===> Epoch[139/1000]): Loss: 0.10810936744061624 Acc: 25924
(train)===> Epoch[140/1000]): Loss: 0.10691046743540898 Acc: 25938
(train)===> Epoch[141/1000]): Loss: 0.10663039447859171 Acc: 25942
(validation)===> Epoch[141/1000]): Acc: 0.953926282051282
(train)===> Epoch[142/1000]): Loss: 0.1043361970345156 Acc: 25968
(train)===> Epoch[143/1000]): Loss: 0.10466045746911588 Acc: 25956
(train)===> Epoch[144/1000]): Loss: 0.10629787185448367 Acc: 25998
(train)===> Epoch[145/1000]): Loss: 0.10531972173043921 Acc: 25974
(train)===> Epoch[146/1000]): Loss: 0.10447438089995512 Acc: 25956
(train)===> Epoch[147/1000]): Loss: 0.10547024326624611 Acc: 25946
(train)===> Epoch[148/1000]): Loss: 0.10207832129915503 Acc: 25979
(train)===> Epoch[149/1000]): Loss: 0.10531572160485805 Acc: 25935
(train)===> Epoch[150/1000]): Loss: 0.10570796663184912 Acc: 25936
(train)===> Epoch[151/1000]): Loss: 0.10287638902089027 Acc: 25970
(validation)===> Epoch[151/1000]): Acc: 0.9491185897435898
(train)===> Epoch[152/1000]): Loss: 0.10321305388244063 Acc: 25966
(train)===> Epoch[153/1000]): Loss: 0.10089789141155331 Acc: 26007
(train)===> Epoch[154/1000]): Loss: 0.10059924345383883 Acc: 25994
(train)===> Epoch[155/1000]): Loss: 0.10275474334945302 Acc: 25957
(train)===> Epoch[156/1000]): Loss: 0.10068494798681935 Acc: 26019
(train)===> Epoch[157/1000]): Loss: 0.10340142192765896 Acc: 25945
(train)===> Epoch[158/1000]): Loss: 0.10078107609884752 Acc: 25983
(train)===> Epoch[159/1000]): Loss: 0.10119713255980729 Acc: 25985
(train)===> Epoch[160/1000]): Loss: 0.1004419863277121 Acc: 25992
(train)===> Epoch[161/1000]): Loss: 0.10256846479168984 Acc: 25976
(validation)===> Epoch[161/1000]): Acc: 0.9467147435897436
(train)===> Epoch[162/1000]): Loss: 0.10021702354804841 Acc: 26001
(train)===> Epoch[163/1000]): Loss: 0.10204307296072222 Acc: 25969
(train)===> Epoch[164/1000]): Loss: 0.09933633935104641 Acc: 26010
(train)===> Epoch[165/1000]): Loss: 0.10024798607935954 Acc: 25997
(train)===> Epoch[166/1000]): Loss: 0.09901227032203859 Acc: 25989
(train)===> Epoch[167/1000]): Loss: 0.1006207314503519 Acc: 26000
(train)===> Epoch[168/1000]): Loss: 0.09664497156173989 Acc: 26034
(train)===> Epoch[169/1000]): Loss: 0.09782404200375218 Acc: 26009
(train)===> Epoch[170/1000]): Loss: 0.09828860586566622 Acc: 26025
(train)===> Epoch[171/1000]): Loss: 0.09646203027343528 Acc: 26049
(validation)===> Epoch[171/1000]): Acc: 0.9491185897435898
(train)===> Epoch[172/1000]): Loss: 0.09831742514942435 Acc: 26016
(train)===> Epoch[173/1000]): Loss: 0.09550729533325598 Acc: 26042
(train)===> Epoch[174/1000]): Loss: 0.09696173460406395 Acc: 26024
(train)===> Epoch[175/1000]): Loss: 0.0977905794995839 Acc: 26032
(train)===> Epoch[176/1000]): Loss: 0.09533092783954253 Acc: 26040
(train)===> Epoch[177/1000]): Loss: 0.09602360857646222 Acc: 26027
(train)===> Epoch[178/1000]): Loss: 0.0987195765373967 Acc: 25984
(train)===> Epoch[179/1000]): Loss: 0.09397309846211567 Acc: 26027
(train)===> Epoch[180/1000]): Loss: 0.0967953062733534 Acc: 26026
(train)===> Epoch[181/1000]): Loss: 0.09666363861756902 Acc: 26025
(validation)===> Epoch[181/1000]): Acc: 0.9491185897435898
(train)===> Epoch[182/1000]): Loss: 0.09367790656726172 Acc: 26041
(train)===> Epoch[183/1000]): Loss: 0.09373232086284211 Acc: 26060
(train)===> Epoch[184/1000]): Loss: 0.09846364748343435 Acc: 25999
(train)===> Epoch[185/1000]): Loss: 0.09719910491213678 Acc: 25988
(train)===> Epoch[186/1000]): Loss: 0.09451368350907269 Acc: 26031
(train)===> Epoch[187/1000]): Loss: 0.09711628043559563 Acc: 26024
(train)===> Epoch[188/1000]): Loss: 0.09156666525513503 Acc: 26065
(train)===> Epoch[189/1000]): Loss: 0.09358276970100515 Acc: 26082
(train)===> Epoch[190/1000]): Loss: 0.09150987840091664 Acc: 26055
(train)===> Epoch[191/1000]): Loss: 0.09407057377980967 Acc: 26084
(validation)===> Epoch[191/1000]): Acc: 0.9503205128205128
(train)===> Epoch[192/1000]): Loss: 0.09406745157507641 Acc: 26063
(train)===> Epoch[193/1000]): Loss: 0.0907330486985397 Acc: 26059
(train)===> Epoch[194/1000]): Loss: 0.09412667741932654 Acc: 26033
(train)===> Epoch[195/1000]): Loss: 0.08981743084395087 Acc: 26118
(train)===> Epoch[196/1000]): Loss: 0.09398792755531239 Acc: 26063
(train)===> Epoch[197/1000]): Loss: 0.09022963845177676 Acc: 26055
(train)===> Epoch[198/1000]): Loss: 0.09169920550929177 Acc: 26075
(train)===> Epoch[199/1000]): Loss: 0.0905814394819376 Acc: 26058
(train)===> Epoch[200/1000]): Loss: 0.09128669234359914 Acc: 26067
(train)===> Epoch[201/1000]): Loss: 0.09064543823050142 Acc: 26074
(validation)===> Epoch[201/1000]): Acc: 0.9499198717948718
(train)===> Epoch[202/1000]): Loss: 0.09184103646269172 Acc: 26076
(train)===> Epoch[203/1000]): Loss: 0.0877523841270003 Acc: 26125
(train)===> Epoch[204/1000]): Loss: 0.08928538277090455 Acc: 26116
(train)===> Epoch[205/1000]): Loss: 0.08523131022561617 Acc: 26141
(train)===> Epoch[206/1000]): Loss: 0.09008621910671005 Acc: 26115
(train)===> Epoch[207/1000]): Loss: 0.08835689295879667 Acc: 26118
(train)===> Epoch[208/1000]): Loss: 0.09124480498923679 Acc: 26103
(train)===> Epoch[209/1000]): Loss: 0.09317179134606678 Acc: 26070
(train)===> Epoch[210/1000]): Loss: 0.09025237742466334 Acc: 26069
(train)===> Epoch[211/1000]): Loss: 0.0888240058616582 Acc: 26118
(validation)===> Epoch[211/1000]): Acc: 0.9499198717948718
(train)===> Epoch[212/1000]): Loss: 0.08839073146067357 Acc: 26122
(train)===> Epoch[213/1000]): Loss: 0.0901500236800477 Acc: 26062
(train)===> Epoch[214/1000]): Loss: 0.08524222120492234 Acc: 26101
(train)===> Epoch[215/1000]): Loss: 0.08954716501469924 Acc: 26075
(train)===> Epoch[216/1000]): Loss: 0.0861834466917499 Acc: 26109
(train)===> Epoch[217/1000]): Loss: 0.0848642457652652 Acc: 26125
(train)===> Epoch[218/1000]): Loss: 0.08546869930393125 Acc: 26124
(train)===> Epoch[219/1000]): Loss: 0.08853907228255034 Acc: 26111
(train)===> Epoch[220/1000]): Loss: 0.08564203808132807 Acc: 26109
(train)===> Epoch[221/1000]): Loss: 0.08693459322299982 Acc: 26119
(validation)===> Epoch[221/1000]): Acc: 0.952323717948718
(train)===> Epoch[222/1000]): Loss: 0.08694279084375879 Acc: 26075
(train)===> Epoch[223/1000]): Loss: 0.08600279226934547 Acc: 26095
(train)===> Epoch[224/1000]): Loss: 0.08633479560701052 Acc: 26133
(train)===> Epoch[225/1000]): Loss: 0.08726279055279394 Acc: 26119
(train)===> Epoch[226/1000]): Loss: 0.0859480638194148 Acc: 26117
(train)===> Epoch[227/1000]): Loss: 0.08196215407874193 Acc: 26167
(train)===> Epoch[228/1000]): Loss: 0.08597059698439156 Acc: 26112
(train)===> Epoch[229/1000]): Loss: 0.08829616209284154 Acc: 26085
(train)===> Epoch[230/1000]): Loss: 0.08748443626672596 Acc: 26123
(train)===> Epoch[231/1000]): Loss: 0.08323450816127163 Acc: 26147
(validation)===> Epoch[231/1000]): Acc: 0.9551282051282052
(train)===> Epoch[232/1000]): Loss: 0.08428558689761123 Acc: 26147
(train)===> Epoch[233/1000]): Loss: 0.08533223064488026 Acc: 26129
(train)===> Epoch[234/1000]): Loss: 0.0868329413062639 Acc: 26123
(train)===> Epoch[235/1000]): Loss: 0.08563870056631864 Acc: 26110
(train)===> Epoch[236/1000]): Loss: 0.08631254648767642 Acc: 26117
(train)===> Epoch[237/1000]): Loss: 0.08308103833692668 Acc: 26141
(train)===> Epoch[238/1000]): Loss: 0.08587111741959202 Acc: 26109
(train)===> Epoch[239/1000]): Loss: 0.08263926908170309 Acc: 26154
(train)===> Epoch[240/1000]): Loss: 0.08632013438636714 Acc: 26125
(train)===> Epoch[241/1000]): Loss: 0.08301859187524134 Acc: 26166
(validation)===> Epoch[241/1000]): Acc: 0.9587339743589743
(train)===> Epoch[242/1000]): Loss: 0.08506389836296262 Acc: 26151
(train)===> Epoch[243/1000]): Loss: 0.07900913561099254 Acc: 26200
(train)===> Epoch[244/1000]): Loss: 0.08340720507159223 Acc: 26144
(train)===> Epoch[245/1000]): Loss: 0.08196143947338193 Acc: 26161
(train)===> Epoch[246/1000]): Loss: 0.07752641215654985 Acc: 26204
(train)===> Epoch[247/1000]): Loss: 0.08159016153051771 Acc: 26153
(train)===> Epoch[248/1000]): Loss: 0.08047475426229973 Acc: 26200
(train)===> Epoch[249/1000]): Loss: 0.08460217270327644 Acc: 26155
(train)===> Epoch[250/1000]): Loss: 0.08478612816204581 Acc: 26159
(train)===> Epoch[251/1000]): Loss: 0.08037226182583392 Acc: 26171
(validation)===> Epoch[251/1000]): Acc: 0.9503205128205128
(train)===> Epoch[252/1000]): Loss: 0.08315676238140059 Acc: 26144
(train)===> Epoch[253/1000]): Loss: 0.08383308132256505 Acc: 26144
(train)===> Epoch[254/1000]): Loss: 0.08045363126680999 Acc: 26159
(train)===> Epoch[255/1000]): Loss: 0.08470811842854471 Acc: 26124
(train)===> Epoch[256/1000]): Loss: 0.08227765770748503 Acc: 26156
(train)===> Epoch[257/1000]): Loss: 0.08203842547985414 Acc: 26180
(train)===> Epoch[258/1000]): Loss: 0.08134771873090511 Acc: 26171
(train)===> Epoch[259/1000]): Loss: 0.07696028971810097 Acc: 26232
(train)===> Epoch[260/1000]): Loss: 0.07697649926805507 Acc: 26207
(train)===> Epoch[261/1000]): Loss: 0.07918965119664997 Acc: 26167
(validation)===> Epoch[261/1000]): Acc: 0.9499198717948718
(train)===> Epoch[262/1000]): Loss: 0.07995096913974667 Acc: 26201
(train)===> Epoch[263/1000]): Loss: 0.07988278470234392 Acc: 26201
(train)===> Epoch[264/1000]): Loss: 0.08066512761757026 Acc: 26183
(train)===> Epoch[265/1000]): Loss: 0.07830786911633547 Acc: 26221
(train)===> Epoch[266/1000]): Loss: 0.07738014697064068 Acc: 26231
(train)===> Epoch[267/1000]): Loss: 0.08064955716505821 Acc: 26161
(train)===> Epoch[268/1000]): Loss: 0.07818938154647578 Acc: 26177
(train)===> Epoch[269/1000]): Loss: 0.07672540293541913 Acc: 26221
(train)===> Epoch[270/1000]): Loss: 0.08049564924967112 Acc: 26192
(train)===> Epoch[271/1000]): Loss: 0.07767820487245737 Acc: 26199
(validation)===> Epoch[271/1000]): Acc: 0.9491185897435898
(train)===> Epoch[272/1000]): Loss: 0.0774138954837504 Acc: 26214
(train)===> Epoch[273/1000]): Loss: 0.08124701240080061 Acc: 26183
(train)===> Epoch[274/1000]): Loss: 0.07828128008025911 Acc: 26197
(train)===> Epoch[275/1000]): Loss: 0.0785028971798027 Acc: 26208
(train)===> Epoch[276/1000]): Loss: 0.07963304483550747 Acc: 26175
(train)===> Epoch[277/1000]): Loss: 0.07289456926295061 Acc: 26245
(train)===> Epoch[278/1000]): Loss: 0.07931629503300673 Acc: 26194
(train)===> Epoch[279/1000]): Loss: 0.07356467078862414 Acc: 26238
(train)===> Epoch[280/1000]): Loss: 0.0791195063451371 Acc: 26185
(train)===> Epoch[281/1000]): Loss: 0.07775744434552286 Acc: 26201
(validation)===> Epoch[281/1000]): Acc: 0.952323717948718
(train)===> Epoch[282/1000]): Loss: 0.07520605408256953 Acc: 26230
(train)===> Epoch[283/1000]): Loss: 0.07747150639695888 Acc: 26220
(train)===> Epoch[284/1000]): Loss: 0.07752504905645947 Acc: 26209
(train)===> Epoch[285/1000]): Loss: 0.07668012195220326 Acc: 26193
(train)===> Epoch[286/1000]): Loss: 0.0801739134602337 Acc: 26152
(train)===> Epoch[287/1000]): Loss: 0.07721998893839443 Acc: 26210
(train)===> Epoch[288/1000]): Loss: 0.0770019929581753 Acc: 26210
(train)===> Epoch[289/1000]): Loss: 0.07788464675863185 Acc: 26190
(train)===> Epoch[290/1000]): Loss: 0.07642745848461945 Acc: 26222
(train)===> Epoch[291/1000]): Loss: 0.07966374748800119 Acc: 26194
(validation)===> Epoch[291/1000]): Acc: 0.9515224358974359
(train)===> Epoch[292/1000]): Loss: 0.07144421988969886 Acc: 26264
(train)===> Epoch[293/1000]): Loss: 0.07829285332503898 Acc: 26209
(train)===> Epoch[294/1000]): Loss: 0.07533471726407595 Acc: 26219
(train)===> Epoch[295/1000]): Loss: 0.07746681509508511 Acc: 26198
(train)===> Epoch[296/1000]): Loss: 0.0775357813999109 Acc: 26204
(train)===> Epoch[297/1000]): Loss: 0.07636775121959972 Acc: 26210
(train)===> Epoch[298/1000]): Loss: 0.0728155310683819 Acc: 26260
(train)===> Epoch[299/1000]): Loss: 0.07564430248607264 Acc: 26229
(train)===> Epoch[300/1000]): Loss: 0.07432490616213891 Acc: 26237
(train)===> Epoch[301/1000]): Loss: 0.07648102597791402 Acc: 26224
(validation)===> Epoch[301/1000]): Acc: 0.9515224358974359
(train)===> Epoch[302/1000]): Loss: 0.07430182508637596 Acc: 26250
(train)===> Epoch[303/1000]): Loss: 0.07476094466547817 Acc: 26236
(train)===> Epoch[304/1000]): Loss: 0.07028462317044405 Acc: 26282
(train)===> Epoch[305/1000]): Loss: 0.07426866447230066 Acc: 26231
(train)===> Epoch[306/1000]): Loss: 0.0742618718899061 Acc: 26221
(train)===> Epoch[307/1000]): Loss: 0.07153981879813652 Acc: 26275
(train)===> Epoch[308/1000]): Loss: 0.07391492411994205 Acc: 26238
(train)===> Epoch[309/1000]): Loss: 0.0741369839881562 Acc: 26220
(train)===> Epoch[310/1000]): Loss: 0.07314925350363842 Acc: 26221
(train)===> Epoch[311/1000]): Loss: 0.07056951070217657 Acc: 26262
(validation)===> Epoch[311/1000]): Acc: 0.9475160256410257
(train)===> Epoch[312/1000]): Loss: 0.07158910912282396 Acc: 26276
(train)===> Epoch[313/1000]): Loss: 0.07208704927299088 Acc: 26245
(train)===> Epoch[314/1000]): Loss: 0.07198317035271688 Acc: 26273
(train)===> Epoch[315/1000]): Loss: 0.07170375363985322 Acc: 26253
(train)===> Epoch[316/1000]): Loss: 0.07377569763224369 Acc: 26223
(train)===> Epoch[317/1000]): Loss: 0.07599377120687956 Acc: 26224
(train)===> Epoch[318/1000]): Loss: 0.07065515729627458 Acc: 26262
(train)===> Epoch[319/1000]): Loss: 0.07296472732110432 Acc: 26244
(train)===> Epoch[320/1000]): Loss: 0.07155970542640773 Acc: 26257
(train)===> Epoch[321/1000]): Loss: 0.07247869585001414 Acc: 26245
(validation)===> Epoch[321/1000]): Acc: 0.9563301282051282
(train)===> Epoch[322/1000]): Loss: 0.07186386788445312 Acc: 26238
(train)===> Epoch[323/1000]): Loss: 0.07096056936025583 Acc: 26248
(train)===> Epoch[324/1000]): Loss: 0.07478338446149561 Acc: 26242
(train)===> Epoch[325/1000]): Loss: 0.07142124539396043 Acc: 26264
(train)===> Epoch[326/1000]): Loss: 0.06931561546957649 Acc: 26307
(train)===> Epoch[327/1000]): Loss: 0.07107355165120541 Acc: 26256
(train)===> Epoch[328/1000]): Loss: 0.07265513449367546 Acc: 26247
(train)===> Epoch[329/1000]): Loss: 0.076339102159929 Acc: 26211
(train)===> Epoch[330/1000]): Loss: 0.07283869694869727 Acc: 26262
(train)===> Epoch[331/1000]): Loss: 0.07172618409831102 Acc: 26247
(validation)===> Epoch[331/1000]): Acc: 0.9543269230769231
(train)===> Epoch[332/1000]): Loss: 0.06871014326366189 Acc: 26287
(train)===> Epoch[333/1000]): Loss: 0.06991138253936148 Acc: 26252
(train)===> Epoch[334/1000]): Loss: 0.07115717210326868 Acc: 26261
(train)===> Epoch[335/1000]): Loss: 0.06931489827708645 Acc: 26302
(train)===> Epoch[336/1000]): Loss: 0.07211401292638336 Acc: 26279
(train)===> Epoch[337/1000]): Loss: 0.07134799955018978 Acc: 26248
(train)===> Epoch[338/1000]): Loss: 0.06956596967969932 Acc: 26302
(train)===> Epoch[339/1000]): Loss: 0.06978424967901509 Acc: 26284
(train)===> Epoch[340/1000]): Loss: 0.06958739116960459 Acc: 26306
(train)===> Epoch[341/1000]): Loss: 0.06852828829401042 Acc: 26288
(validation)===> Epoch[341/1000]): Acc: 0.9515224358974359
(train)===> Epoch[342/1000]): Loss: 0.0726988938539743 Acc: 26250
(train)===> Epoch[343/1000]): Loss: 0.0708702831692781 Acc: 26291
(train)===> Epoch[344/1000]): Loss: 0.06970564157739645 Acc: 26271
(train)===> Epoch[345/1000]): Loss: 0.07151570593199362 Acc: 26273
(train)===> Epoch[346/1000]): Loss: 0.06967677324656354 Acc: 26258
(train)===> Epoch[347/1000]): Loss: 0.0686226334188337 Acc: 26285
(train)===> Epoch[348/1000]): Loss: 0.06946672643855602 Acc: 26265
(train)===> Epoch[349/1000]): Loss: 0.06974575281997086 Acc: 26257
(train)===> Epoch[350/1000]): Loss: 0.07018633983639953 Acc: 26254
(train)===> Epoch[351/1000]): Loss: 0.07027945911396741 Acc: 26270
(validation)===> Epoch[351/1000]): Acc: 0.953926282051282
(train)===> Epoch[352/1000]): Loss: 0.06836371683358541 Acc: 26294
(train)===> Epoch[353/1000]): Loss: 0.0714366466621039 Acc: 26265
(train)===> Epoch[354/1000]): Loss: 0.06686190263127062 Acc: 26309
(train)===> Epoch[355/1000]): Loss: 0.06860292998901314 Acc: 26293
(train)===> Epoch[356/1000]): Loss: 0.06604147116452315 Acc: 26308
(train)===> Epoch[357/1000]): Loss: 0.06836609892002936 Acc: 26290
(train)===> Epoch[358/1000]): Loss: 0.0719781794215855 Acc: 26254
(train)===> Epoch[359/1000]): Loss: 0.06640827415772052 Acc: 26322
(train)===> Epoch[360/1000]): Loss: 0.0683339476804393 Acc: 26298
(train)===> Epoch[361/1000]): Loss: 0.06567344654820453 Acc: 26321
(validation)===> Epoch[361/1000]): Acc: 0.9463141025641025
(train)===> Epoch[362/1000]): Loss: 0.06820894806975421 Acc: 26286
(train)===> Epoch[363/1000]): Loss: 0.06680271652418757 Acc: 26291
(train)===> Epoch[364/1000]): Loss: 0.06474688077442822 Acc: 26321
(train)===> Epoch[365/1000]): Loss: 0.0693667606735987 Acc: 26278
(train)===> Epoch[366/1000]): Loss: 0.06731645368712105 Acc: 26274
(train)===> Epoch[367/1000]): Loss: 0.0651623329342367 Acc: 26314
(train)===> Epoch[368/1000]): Loss: 0.0667252701700548 Acc: 26307
(train)===> Epoch[369/1000]): Loss: 0.0709537582033957 Acc: 26259
(train)===> Epoch[370/1000]): Loss: 0.06586636648559833 Acc: 26323
(train)===> Epoch[371/1000]): Loss: 0.0650854739548545 Acc: 26293
(validation)===> Epoch[371/1000]): Acc: 0.9511217948717948
(train)===> Epoch[372/1000]): Loss: 0.06724839513201152 Acc: 26307
(train)===> Epoch[373/1000]): Loss: 0.06468213690697014 Acc: 26324
(train)===> Epoch[374/1000]): Loss: 0.06679001455847836 Acc: 26304
(train)===> Epoch[375/1000]): Loss: 0.06666614271085394 Acc: 26302
(train)===> Epoch[376/1000]): Loss: 0.06654206657618501 Acc: 26296
(train)===> Epoch[377/1000]): Loss: 0.06717148611671571 Acc: 26315
(train)===> Epoch[378/1000]): Loss: 0.06923629966234865 Acc: 26249
(train)===> Epoch[379/1000]): Loss: 0.06478975927169633 Acc: 26335
(train)===> Epoch[380/1000]): Loss: 0.06566529322167833 Acc: 26314
(train)===> Epoch[381/1000]): Loss: 0.06728857601251713 Acc: 26321
(validation)===> Epoch[381/1000]): Acc: 0.9563301282051282
(train)===> Epoch[382/1000]): Loss: 0.06622524522444027 Acc: 26315
(train)===> Epoch[383/1000]): Loss: 0.06307900675092418 Acc: 26337
(train)===> Epoch[384/1000]): Loss: 0.0629231861157613 Acc: 26333
(train)===> Epoch[385/1000]): Loss: 0.06661221872785095 Acc: 26298
(train)===> Epoch[386/1000]): Loss: 0.06659142620587218 Acc: 26289
(train)===> Epoch[387/1000]): Loss: 0.07127422191016825 Acc: 26276
(train)===> Epoch[388/1000]): Loss: 0.06483615003858038 Acc: 26314
(train)===> Epoch[389/1000]): Loss: 0.0656939621764786 Acc: 26321
(train)===> Epoch[390/1000]): Loss: 0.0679910255224398 Acc: 26302
(train)===> Epoch[391/1000]): Loss: 0.0634529029667342 Acc: 26339
(validation)===> Epoch[391/1000]): Acc: 0.9599358974358975
(train)===> Epoch[392/1000]): Loss: 0.06344743509336663 Acc: 26347
(train)===> Epoch[393/1000]): Loss: 0.06397531649004887 Acc: 26335
(train)===> Epoch[394/1000]): Loss: 0.0637367835695327 Acc: 26313
(train)===> Epoch[395/1000]): Loss: 0.06481841067405252 Acc: 26318
(train)===> Epoch[396/1000]): Loss: 0.06539754613110182 Acc: 26314
(train)===> Epoch[397/1000]): Loss: 0.06293572173863117 Acc: 26340
(train)===> Epoch[398/1000]): Loss: 0.06468803982854314 Acc: 26333
(train)===> Epoch[399/1000]): Loss: 0.06273157360151664 Acc: 26368
(train)===> Epoch[400/1000]): Loss: 0.06492436957830947 Acc: 26318
(train)===> Epoch[401/1000]): Loss: 0.06456058706110453 Acc: 26306
(validation)===> Epoch[401/1000]): Acc: 0.9535256410256411
(train)===> Epoch[402/1000]): Loss: 0.06639114620203859 Acc: 26307
(train)===> Epoch[403/1000]): Loss: 0.06685104624162519 Acc: 26300
(train)===> Epoch[404/1000]): Loss: 0.06425797788873139 Acc: 26353
(train)===> Epoch[405/1000]): Loss: 0.06472747121006253 Acc: 26315
(train)===> Epoch[406/1000]): Loss: 0.062534724776976 Acc: 26332
(train)===> Epoch[407/1000]): Loss: 0.06438414244237856 Acc: 26327
(train)===> Epoch[408/1000]): Loss: 0.06751794294805895 Acc: 26301
(train)===> Epoch[409/1000]): Loss: 0.06571752622152834 Acc: 26306
(train)===> Epoch[410/1000]): Loss: 0.06581188975490465 Acc: 26313
(train)===> Epoch[411/1000]): Loss: 0.06491962857013503 Acc: 26346
(validation)===> Epoch[411/1000]): Acc: 0.9491185897435898
(train)===> Epoch[412/1000]): Loss: 0.06210883798170613 Acc: 26339
(train)===> Epoch[413/1000]): Loss: 0.06657117401800543 Acc: 26291
(train)===> Epoch[414/1000]): Loss: 0.06592456639507636 Acc: 26311
(train)===> Epoch[415/1000]): Loss: 0.06252616695670364 Acc: 26339
(train)===> Epoch[416/1000]): Loss: 0.06294928400969738 Acc: 26347
(train)===> Epoch[417/1000]): Loss: 0.06445919029025314 Acc: 26318
(train)===> Epoch[418/1000]): Loss: 0.0613549306530797 Acc: 26356
(train)===> Epoch[419/1000]): Loss: 0.06367124140598854 Acc: 26355
(train)===> Epoch[420/1000]): Loss: 0.06632757040333541 Acc: 26315
(train)===> Epoch[421/1000]): Loss: 0.06295635660495302 Acc: 26339
(validation)===> Epoch[421/1000]): Acc: 0.9527243589743589
(train)===> Epoch[422/1000]): Loss: 0.06382081206365889 Acc: 26353
(train)===> Epoch[423/1000]): Loss: 0.06148360029411568 Acc: 26373
(train)===> Epoch[424/1000]): Loss: 0.06049118265775073 Acc: 26363
(train)===> Epoch[425/1000]): Loss: 0.06081282473976714 Acc: 26352
(train)===> Epoch[426/1000]): Loss: 0.06448674032513294 Acc: 26337
(train)===> Epoch[427/1000]): Loss: 0.06335642845137597 Acc: 26342
(train)===> Epoch[428/1000]): Loss: 0.0628102097025411 Acc: 26350
(train)===> Epoch[429/1000]): Loss: 0.06265935485169397 Acc: 26345
(train)===> Epoch[430/1000]): Loss: 0.06214003701254087 Acc: 26351
(train)===> Epoch[431/1000]): Loss: 0.061719845987042256 Acc: 26351
(validation)===> Epoch[431/1000]): Acc: 0.953125
(train)===> Epoch[432/1000]): Loss: 0.061779443625882814 Acc: 26359
(train)===> Epoch[433/1000]): Loss: 0.06511076292876962 Acc: 26341
(train)===> Epoch[434/1000]): Loss: 0.05980187834123253 Acc: 26373
(train)===> Epoch[435/1000]): Loss: 0.06323968305644048 Acc: 26302
(train)===> Epoch[436/1000]): Loss: 0.06033398453898357 Acc: 26363
(train)===> Epoch[437/1000]): Loss: 0.06227118781637265 Acc: 26335
(train)===> Epoch[438/1000]): Loss: 0.06206739790219977 Acc: 26324
(train)===> Epoch[439/1000]): Loss: 0.06096495811400531 Acc: 26339
(train)===> Epoch[440/1000]): Loss: 0.0652479768095808 Acc: 26335
(train)===> Epoch[441/1000]): Loss: 0.05903139927771799 Acc: 26363
(validation)===> Epoch[441/1000]): Acc: 0.9555288461538461
(train)===> Epoch[442/1000]): Loss: 0.059714947662353905 Acc: 26386
(train)===> Epoch[443/1000]): Loss: 0.06290762977245448 Acc: 26341
(train)===> Epoch[444/1000]): Loss: 0.06166450093520223 Acc: 26354
(train)===> Epoch[445/1000]): Loss: 0.06335414462056976 Acc: 26358
(train)===> Epoch[446/1000]): Loss: 0.058208710611344354 Acc: 26373
(train)===> Epoch[447/1000]): Loss: 0.060465199670438 Acc: 26359
(train)===> Epoch[448/1000]): Loss: 0.05938029632242196 Acc: 26361
(train)===> Epoch[449/1000]): Loss: 0.06031550959000392 Acc: 26355
(train)===> Epoch[450/1000]): Loss: 0.06499186042926308 Acc: 26338
(train)===> Epoch[451/1000]): Loss: 0.059449253895822216 Acc: 26377
(validation)===> Epoch[451/1000]): Acc: 0.953125
(train)===> Epoch[452/1000]): Loss: 0.06104811911322974 Acc: 26362
(train)===> Epoch[453/1000]): Loss: 0.06026839831790882 Acc: 26370
(train)===> Epoch[454/1000]): Loss: 0.059320148242075654 Acc: 26361
(train)===> Epoch[455/1000]): Loss: 0.06266914530283374 Acc: 26343
(train)===> Epoch[456/1000]): Loss: 0.060190107493668 Acc: 26370
(train)===> Epoch[457/1000]): Loss: 0.05948591470329041 Acc: 26378
(train)===> Epoch[458/1000]): Loss: 0.06254764620962414 Acc: 26348
(train)===> Epoch[459/1000]): Loss: 0.06016707401435086 Acc: 26359
(train)===> Epoch[460/1000]): Loss: 0.06128517405025996 Acc: 26369
(train)===> Epoch[461/1000]): Loss: 0.06131135831275102 Acc: 26374
(validation)===> Epoch[461/1000]): Acc: 0.953926282051282
(train)===> Epoch[462/1000]): Loss: 0.06101571259944922 Acc: 26370
(train)===> Epoch[463/1000]): Loss: 0.06087288116779609 Acc: 26349
(train)===> Epoch[464/1000]): Loss: 0.058338761235633786 Acc: 26365
(train)===> Epoch[465/1000]): Loss: 0.06027958458267382 Acc: 26346
(train)===> Epoch[466/1000]): Loss: 0.05887335361780121 Acc: 26375
(train)===> Epoch[467/1000]): Loss: 0.05637904483882484 Acc: 26387
(train)===> Epoch[468/1000]): Loss: 0.060856370208895526 Acc: 26371
(train)===> Epoch[469/1000]): Loss: 0.06103033305979783 Acc: 26350
(train)===> Epoch[470/1000]): Loss: 0.061147823661008315 Acc: 26347
(train)===> Epoch[471/1000]): Loss: 0.05923964808564501 Acc: 26381
(validation)===> Epoch[471/1000]): Acc: 0.952323717948718
(train)===> Epoch[472/1000]): Loss: 0.060817633099597375 Acc: 26378
(train)===> Epoch[473/1000]): Loss: 0.05844335869118361 Acc: 26382
(train)===> Epoch[474/1000]): Loss: 0.059150389480822595 Acc: 26390
(train)===> Epoch[475/1000]): Loss: 0.06007500061645855 Acc: 26374
(train)===> Epoch[476/1000]): Loss: 0.05992118950884555 Acc: 26357
(train)===> Epoch[477/1000]): Loss: 0.058494217425027355 Acc: 26358
(train)===> Epoch[478/1000]): Loss: 0.05949615117719927 Acc: 26387
(train)===> Epoch[479/1000]): Loss: 0.05856357861283695 Acc: 26393
(train)===> Epoch[480/1000]): Loss: 0.0611335916705695 Acc: 26379
(train)===> Epoch[481/1000]): Loss: 0.05689733294767913 Acc: 26421
(validation)===> Epoch[481/1000]): Acc: 0.9487179487179487
(train)===> Epoch[482/1000]): Loss: 0.05631565355591814 Acc: 26405
(train)===> Epoch[483/1000]): Loss: 0.058164449532531776 Acc: 26398
(train)===> Epoch[484/1000]): Loss: 0.05821544382358396 Acc: 26378
(train)===> Epoch[485/1000]): Loss: 0.05879652304984099 Acc: 26390
(train)===> Epoch[486/1000]): Loss: 0.058455929620248995 Acc: 26364
(train)===> Epoch[487/1000]): Loss: 0.06088965327529823 Acc: 26338
(train)===> Epoch[488/1000]): Loss: 0.059083334848311235 Acc: 26377
(train)===> Epoch[489/1000]): Loss: 0.05548921037540547 Acc: 26383
(train)===> Epoch[490/1000]): Loss: 0.058808879666871004 Acc: 26366
(train)===> Epoch[491/1000]): Loss: 0.0581232990943462 Acc: 26386
(validation)===> Epoch[491/1000]): Acc: 0.9515224358974359
(train)===> Epoch[492/1000]): Loss: 0.05637786199610832 Acc: 26371
(train)===> Epoch[493/1000]): Loss: 0.06090613613635154 Acc: 26352
(train)===> Epoch[494/1000]): Loss: 0.060584545254955144 Acc: 26361
(train)===> Epoch[495/1000]): Loss: 0.05966576352392516 Acc: 26355
(train)===> Epoch[496/1000]): Loss: 0.05829209917072303 Acc: 26370
(train)===> Epoch[497/1000]): Loss: 0.059578895167339205 Acc: 26369
(train)===> Epoch[498/1000]): Loss: 0.05868202150686522 Acc: 26374
(train)===> Epoch[499/1000]): Loss: 0.056675993214690926 Acc: 26384
(train)===> Epoch[500/1000]): Loss: 0.0560393573532673 Acc: 26385
(train)===> Epoch[501/1000]): Loss: 0.05885710959232052 Acc: 26357
(validation)===> Epoch[501/1000]): Acc: 0.9511217948717948
(train)===> Epoch[502/1000]): Loss: 0.05646908899654155 Acc: 26389
(train)===> Epoch[503/1000]): Loss: 0.05700761919748262 Acc: 26397
(train)===> Epoch[504/1000]): Loss: 0.05852566604312252 Acc: 26388
(train)===> Epoch[505/1000]): Loss: 0.05986602753931723 Acc: 26372
(train)===> Epoch[506/1000]): Loss: 0.05748406758160285 Acc: 26394
(train)===> Epoch[507/1000]): Loss: 0.0550182914126868 Acc: 26419
(train)===> Epoch[508/1000]): Loss: 0.05757882171852462 Acc: 26395
(train)===> Epoch[509/1000]): Loss: 0.05838761242181771 Acc: 26376
(train)===> Epoch[510/1000]): Loss: 0.05410451115155484 Acc: 26420
(train)===> Epoch[511/1000]): Loss: 0.05369254916070156 Acc: 26428
(validation)===> Epoch[511/1000]): Acc: 0.9555288461538461
(train)===> Epoch[512/1000]): Loss: 0.05848877381803269 Acc: 26375
(train)===> Epoch[513/1000]): Loss: 0.057275303221371796 Acc: 26400
(train)===> Epoch[514/1000]): Loss: 0.05585026362636557 Acc: 26406
(train)===> Epoch[515/1000]): Loss: 0.056980393028369006 Acc: 26377
(train)===> Epoch[516/1000]): Loss: 0.05739020446156132 Acc: 26394
(train)===> Epoch[517/1000]): Loss: 0.056991570216057205 Acc: 26401
(train)===> Epoch[518/1000]): Loss: 0.05665704948305549 Acc: 26414
(train)===> Epoch[519/1000]): Loss: 0.05652888583333503 Acc: 26405
(train)===> Epoch[520/1000]): Loss: 0.05514294297584823 Acc: 26436
(train)===> Epoch[521/1000]): Loss: 0.05742563442780575 Acc: 26394
(validation)===> Epoch[521/1000]): Acc: 0.9527243589743589
(train)===> Epoch[522/1000]): Loss: 0.056966484241152214 Acc: 26436
(train)===> Epoch[523/1000]): Loss: 0.05664124435937638 Acc: 26387
(train)===> Epoch[524/1000]): Loss: 0.056818900697349205 Acc: 26401
(train)===> Epoch[525/1000]): Loss: 0.05347307496914322 Acc: 26421
(train)===> Epoch[526/1000]): Loss: 0.0548908180201032 Acc: 26434
(train)===> Epoch[527/1000]): Loss: 0.0586018274016147 Acc: 26380
(train)===> Epoch[528/1000]): Loss: 0.055994346893819484 Acc: 26412
(train)===> Epoch[529/1000]): Loss: 0.05410207467343914 Acc: 26430
(train)===> Epoch[530/1000]): Loss: 0.05651053589505457 Acc: 26397
(train)===> Epoch[531/1000]): Loss: 0.055376798433258316 Acc: 26412
(validation)===> Epoch[531/1000]): Acc: 0.9535256410256411
(train)===> Epoch[532/1000]): Loss: 0.05487734334368587 Acc: 26395
(train)===> Epoch[533/1000]): Loss: 0.05463397301868437 Acc: 26408
(train)===> Epoch[534/1000]): Loss: 0.056036645546555554 Acc: 26403
(train)===> Epoch[535/1000]): Loss: 0.05435760709901743 Acc: 26404
(train)===> Epoch[536/1000]): Loss: 0.05421982115829217 Acc: 26447
(train)===> Epoch[537/1000]): Loss: 0.056988784292327885 Acc: 26402
(train)===> Epoch[538/1000]): Loss: 0.05561421284531718 Acc: 26412
(train)===> Epoch[539/1000]): Loss: 0.05947783594782912 Acc: 26379
(train)===> Epoch[540/1000]): Loss: 0.05720236538986797 Acc: 26396
(train)===> Epoch[541/1000]): Loss: 0.057043423192606545 Acc: 26394
(validation)===> Epoch[541/1000]): Acc: 0.9567307692307693
(train)===> Epoch[542/1000]): Loss: 0.05493324996146981 Acc: 26400
(train)===> Epoch[543/1000]): Loss: 0.054435414444619815 Acc: 26399
(train)===> Epoch[544/1000]): Loss: 0.059059166368274005 Acc: 26378
(train)===> Epoch[545/1000]): Loss: 0.054771795274906554 Acc: 26421
(train)===> Epoch[546/1000]): Loss: 0.05468803905547903 Acc: 26413
(train)===> Epoch[547/1000]): Loss: 0.05768018573657512 Acc: 26387
(train)===> Epoch[548/1000]): Loss: 0.05364371559664499 Acc: 26417
(train)===> Epoch[549/1000]): Loss: 0.05518164922596091 Acc: 26407
(train)===> Epoch[550/1000]): Loss: 0.054653225188981996 Acc: 26407
(train)===> Epoch[551/1000]): Loss: 0.053199002593910555 Acc: 26420
(validation)===> Epoch[551/1000]): Acc: 0.9519230769230769
(train)===> Epoch[552/1000]): Loss: 0.057663239162601035 Acc: 26381
(train)===> Epoch[553/1000]): Loss: 0.0560925682539877 Acc: 26405
(train)===> Epoch[554/1000]): Loss: 0.05642635977192123 Acc: 26387
(train)===> Epoch[555/1000]): Loss: 0.05365704920921571 Acc: 26399
(train)===> Epoch[556/1000]): Loss: 0.054603607257752894 Acc: 26406
(train)===> Epoch[557/1000]): Loss: 0.05520640127692648 Acc: 26398
(train)===> Epoch[558/1000]): Loss: 0.055502150753610265 Acc: 26417
(train)===> Epoch[559/1000]): Loss: 0.05054936374951319 Acc: 26454
(train)===> Epoch[560/1000]): Loss: 0.05610873124113132 Acc: 26400
(train)===> Epoch[561/1000]): Loss: 0.05173386736925594 Acc: 26458
(validation)===> Epoch[561/1000]): Acc: 0.9499198717948718
(train)===> Epoch[562/1000]): Loss: 0.05396942481024728 Acc: 26404
(train)===> Epoch[563/1000]): Loss: 0.054039623142571824 Acc: 26416
(train)===> Epoch[564/1000]): Loss: 0.05416975280539864 Acc: 26436
(train)===> Epoch[565/1000]): Loss: 0.05276195824615253 Acc: 26440
(train)===> Epoch[566/1000]): Loss: 0.05502168899468386 Acc: 26417
(train)===> Epoch[567/1000]): Loss: 0.05454074561202146 Acc: 26427
(train)===> Epoch[568/1000]): Loss: 0.05519955211170814 Acc: 26407
(train)===> Epoch[569/1000]): Loss: 0.05250271776637987 Acc: 26446
(train)===> Epoch[570/1000]): Loss: 0.05502840925689407 Acc: 26439
(train)===> Epoch[571/1000]): Loss: 0.053529759951382705 Acc: 26407
(validation)===> Epoch[571/1000]): Acc: 0.952323717948718
(train)===> Epoch[572/1000]): Loss: 0.054014504574141926 Acc: 26444
(train)===> Epoch[573/1000]): Loss: 0.05548722856852828 Acc: 26413
(train)===> Epoch[574/1000]): Loss: 0.055294081344182934 Acc: 26398
(train)===> Epoch[575/1000]): Loss: 0.051771495638928515 Acc: 26431
(train)===> Epoch[576/1000]): Loss: 0.05388102020333896 Acc: 26421
(train)===> Epoch[577/1000]): Loss: 0.05242156702140235 Acc: 26449
(train)===> Epoch[578/1000]): Loss: 0.05400018338578576 Acc: 26412
(train)===> Epoch[579/1000]): Loss: 0.05362038224970932 Acc: 26406
(train)===> Epoch[580/1000]): Loss: 0.05173390668998266 Acc: 26458
(train)===> Epoch[581/1000]): Loss: 0.05521359416266854 Acc: 26409
(validation)===> Epoch[581/1000]): Acc: 0.952323717948718
(train)===> Epoch[582/1000]): Loss: 0.05245542171855857 Acc: 26434
(train)===> Epoch[583/1000]): Loss: 0.05271627386587269 Acc: 26405
(train)===> Epoch[584/1000]): Loss: 0.05084095922057599 Acc: 26448
(train)===> Epoch[585/1000]): Loss: 0.05585194462711199 Acc: 26412
(train)===> Epoch[586/1000]): Loss: 0.050790700880642484 Acc: 26439
(train)===> Epoch[587/1000]): Loss: 0.055567704142246085 Acc: 26403
(train)===> Epoch[588/1000]): Loss: 0.05277269594747389 Acc: 26444
(train)===> Epoch[589/1000]): Loss: 0.053193035919325414 Acc: 26447
(train)===> Epoch[590/1000]): Loss: 0.05218792415164289 Acc: 26448
(train)===> Epoch[591/1000]): Loss: 0.05038384389798124 Acc: 26472
(validation)===> Epoch[591/1000]): Acc: 0.9575320512820513
(train)===> Epoch[592/1000]): Loss: 0.05132639292968246 Acc: 26456
(train)===> Epoch[593/1000]): Loss: 0.053745335355100184 Acc: 26443
(train)===> Epoch[594/1000]): Loss: 0.052323051206236655 Acc: 26444
(train)===> Epoch[595/1000]): Loss: 0.051505046617903366 Acc: 26454
(train)===> Epoch[596/1000]): Loss: 0.05293191260947997 Acc: 26425
(train)===> Epoch[597/1000]): Loss: 0.05120475669535245 Acc: 26447
(train)===> Epoch[598/1000]): Loss: 0.052470271378277755 Acc: 26418
(train)===> Epoch[599/1000]): Loss: 0.05416429929618865 Acc: 26428
(train)===> Epoch[600/1000]): Loss: 0.05209734650481398 Acc: 26448
(train)===> Epoch[601/1000]): Loss: 0.05247367726972953 Acc: 26433
(validation)===> Epoch[601/1000]): Acc: 0.953926282051282
(train)===> Epoch[602/1000]): Loss: 0.05063742049859122 Acc: 26449
(train)===> Epoch[603/1000]): Loss: 0.05433556256537066 Acc: 26419
(train)===> Epoch[604/1000]): Loss: 0.052220769848723154 Acc: 26436
(train)===> Epoch[605/1000]): Loss: 0.052530255393764484 Acc: 26456
(train)===> Epoch[606/1000]): Loss: 0.05388102730163179 Acc: 26436
(train)===> Epoch[607/1000]): Loss: 0.05471790999598854 Acc: 26401
(train)===> Epoch[608/1000]): Loss: 0.05172951026728951 Acc: 26452
(train)===> Epoch[609/1000]): Loss: 0.0546461311401246 Acc: 26418
(train)===> Epoch[610/1000]): Loss: 0.05241917354616639 Acc: 26427
(train)===> Epoch[611/1000]): Loss: 0.05020683613382372 Acc: 26445
(validation)===> Epoch[611/1000]): Acc: 0.953926282051282
(train)===> Epoch[612/1000]): Loss: 0.05165837155632904 Acc: 26445
(train)===> Epoch[613/1000]): Loss: 0.04918580138038248 Acc: 26494
(train)===> Epoch[614/1000]): Loss: 0.055041220843252144 Acc: 26415
(train)===> Epoch[615/1000]): Loss: 0.05193868376128816 Acc: 26448
(train)===> Epoch[616/1000]): Loss: 0.052693296197332824 Acc: 26413
(train)===> Epoch[617/1000]): Loss: 0.05261444870322817 Acc: 26426
(train)===> Epoch[618/1000]): Loss: 0.04965224528116681 Acc: 26458
(train)===> Epoch[619/1000]): Loss: 0.05310931690081494 Acc: 26411
(train)===> Epoch[620/1000]): Loss: 0.04995398090227623 Acc: 26451
(train)===> Epoch[621/1000]): Loss: 0.05380168514251006 Acc: 26426
(validation)===> Epoch[621/1000]): Acc: 0.9535256410256411
(train)===> Epoch[622/1000]): Loss: 0.051446355311332785 Acc: 26452
(train)===> Epoch[623/1000]): Loss: 0.05110455843268269 Acc: 26455
(train)===> Epoch[624/1000]): Loss: 0.05072870442196902 Acc: 26451
(train)===> Epoch[625/1000]): Loss: 0.048746849771925324 Acc: 26469
(train)===> Epoch[626/1000]): Loss: 0.04764706329464683 Acc: 26480
(train)===> Epoch[627/1000]): Loss: 0.052316443569905134 Acc: 26437
(train)===> Epoch[628/1000]): Loss: 0.05279177501952532 Acc: 26445
(train)===> Epoch[629/1000]): Loss: 0.04901378506445048 Acc: 26465
(train)===> Epoch[630/1000]): Loss: 0.05142259849191173 Acc: 26445
(train)===> Epoch[631/1000]): Loss: 0.05112850469660964 Acc: 26443
(validation)===> Epoch[631/1000]): Acc: 0.9519230769230769
(train)===> Epoch[632/1000]): Loss: 0.04866370748874518 Acc: 26483
(train)===> Epoch[633/1000]): Loss: 0.0513859145307909 Acc: 26443
(train)===> Epoch[634/1000]): Loss: 0.05242385836694207 Acc: 26422
(train)===> Epoch[635/1000]): Loss: 0.04810700806702827 Acc: 26479
(train)===> Epoch[636/1000]): Loss: 0.05320282824472422 Acc: 26428
(train)===> Epoch[637/1000]): Loss: 0.051950887331712464 Acc: 26452
(train)===> Epoch[638/1000]): Loss: 0.05246103078020727 Acc: 26437
(train)===> Epoch[639/1000]): Loss: 0.05227515632021209 Acc: 26427
(train)===> Epoch[640/1000]): Loss: 0.05189158463178117 Acc: 26444
(train)===> Epoch[641/1000]): Loss: 0.04963156119577426 Acc: 26467
(validation)===> Epoch[641/1000]): Acc: 0.9499198717948718
(train)===> Epoch[642/1000]): Loss: 0.05389975224601681 Acc: 26410
(train)===> Epoch[643/1000]): Loss: 0.048547676185946784 Acc: 26485
(train)===> Epoch[644/1000]): Loss: 0.04735695281023963 Acc: 26481
(train)===> Epoch[645/1000]): Loss: 0.04956798183271607 Acc: 26448
(train)===> Epoch[646/1000]): Loss: 0.052619359722568884 Acc: 26433
(train)===> Epoch[647/1000]): Loss: 0.05442982453149422 Acc: 26409
(train)===> Epoch[648/1000]): Loss: 0.05296366747619137 Acc: 26441
(train)===> Epoch[649/1000]): Loss: 0.049860408445853446 Acc: 26468
(train)===> Epoch[650/1000]): Loss: 0.04982428000786402 Acc: 26451
(train)===> Epoch[651/1000]): Loss: 0.04867065718758079 Acc: 26462
(validation)===> Epoch[651/1000]): Acc: 0.9503205128205128
(train)===> Epoch[652/1000]): Loss: 0.05071422753351208 Acc: 26447
(train)===> Epoch[653/1000]): Loss: 0.05070846809119633 Acc: 26458
(train)===> Epoch[654/1000]): Loss: 0.052035046546695635 Acc: 26448
(train)===> Epoch[655/1000]): Loss: 0.049155131902660736 Acc: 26479
(train)===> Epoch[656/1000]): Loss: 0.05005054335351017 Acc: 26441
(train)===> Epoch[657/1000]): Loss: 0.04831703409946344 Acc: 26484
(train)===> Epoch[658/1000]): Loss: 0.05058420612089635 Acc: 26428
(train)===> Epoch[659/1000]): Loss: 0.04890443580756028 Acc: 26468
(train)===> Epoch[660/1000]): Loss: 0.04900702592118192 Acc: 26440
(train)===> Epoch[661/1000]): Loss: 0.05152891281518793 Acc: 26446
(validation)===> Epoch[661/1000]): Acc: 0.9563301282051282
(train)===> Epoch[662/1000]): Loss: 0.048517705919110414 Acc: 26475
(train)===> Epoch[663/1000]): Loss: 0.049740979998790555 Acc: 26458
(train)===> Epoch[664/1000]): Loss: 0.04660692539136861 Acc: 26465
(train)===> Epoch[665/1000]): Loss: 0.050211630396615727 Acc: 26468
(train)===> Epoch[666/1000]): Loss: 0.04970924992384196 Acc: 26466
(train)===> Epoch[667/1000]): Loss: 0.04659524143036372 Acc: 26496
(train)===> Epoch[668/1000]): Loss: 0.05029416448301735 Acc: 26447
(train)===> Epoch[669/1000]): Loss: 0.05202753719046376 Acc: 26432
(train)===> Epoch[670/1000]): Loss: 0.049092216969682335 Acc: 26460
(train)===> Epoch[671/1000]): Loss: 0.04756928363929983 Acc: 26478
(validation)===> Epoch[671/1000]): Acc: 0.9551282051282052
(train)===> Epoch[672/1000]): Loss: 0.05108830522615329 Acc: 26442
(train)===> Epoch[673/1000]): Loss: 0.05118819092391525 Acc: 26449
(train)===> Epoch[674/1000]): Loss: 0.04912938904006151 Acc: 26487
(train)===> Epoch[675/1000]): Loss: 0.04854657639823455 Acc: 26480
(train)===> Epoch[676/1000]): Loss: 0.0492549942985549 Acc: 26466
(train)===> Epoch[677/1000]): Loss: 0.04860874317058819 Acc: 26483
(train)===> Epoch[678/1000]): Loss: 0.048622596280587384 Acc: 26462
(train)===> Epoch[679/1000]): Loss: 0.0473733666135029 Acc: 26466
(train)===> Epoch[680/1000]): Loss: 0.04740452301642039 Acc: 26501
(train)===> Epoch[681/1000]): Loss: 0.05003721982344646 Acc: 26465
(validation)===> Epoch[681/1000]): Acc: 0.9551282051282052
(train)===> Epoch[682/1000]): Loss: 0.050025637100081254 Acc: 26468
(train)===> Epoch[683/1000]): Loss: 0.04796577055967302 Acc: 26489
(train)===> Epoch[684/1000]): Loss: 0.04888068481886013 Acc: 26481
(train)===> Epoch[685/1000]): Loss: 0.04742201476196383 Acc: 26488
(train)===> Epoch[686/1000]): Loss: 0.04758266608381195 Acc: 26468
(train)===> Epoch[687/1000]): Loss: 0.04839287544523241 Acc: 26462
(train)===> Epoch[688/1000]): Loss: 0.051956765569919044 Acc: 26465
(train)===> Epoch[689/1000]): Loss: 0.04819675323701601 Acc: 26488
(train)===> Epoch[690/1000]): Loss: 0.04866321770100451 Acc: 26462
(train)===> Epoch[691/1000]): Loss: 0.049112818773499656 Acc: 26472
(validation)===> Epoch[691/1000]): Acc: 0.953125
(train)===> Epoch[692/1000]): Loss: 0.04716021291891692 Acc: 26479
(train)===> Epoch[693/1000]): Loss: 0.04859214935135405 Acc: 26464
(train)===> Epoch[694/1000]): Loss: 0.048068454801027505 Acc: 26486
(train)===> Epoch[695/1000]): Loss: 0.04697206642560555 Acc: 26487
(train)===> Epoch[696/1000]): Loss: 0.05292160404766433 Acc: 26435
(train)===> Epoch[697/1000]): Loss: 0.04901631901288437 Acc: 26450
(train)===> Epoch[698/1000]): Loss: 0.04873328317220009 Acc: 26472
(train)===> Epoch[699/1000]): Loss: 0.05085735788874137 Acc: 26441
(train)===> Epoch[700/1000]): Loss: 0.04938664897389253 Acc: 26458
(train)===> Epoch[701/1000]): Loss: 0.04834824525684808 Acc: 26474
(validation)===> Epoch[701/1000]): Acc: 0.9587339743589743
(train)===> Epoch[702/1000]): Loss: 0.05138074710684207 Acc: 26443
(train)===> Epoch[703/1000]): Loss: 0.04910172355049369 Acc: 26472
(train)===> Epoch[704/1000]): Loss: 0.04797602410211432 Acc: 26470
(train)===> Epoch[705/1000]): Loss: 0.046235514802508704 Acc: 26493
(train)===> Epoch[706/1000]): Loss: 0.045035618820256425 Acc: 26514
(train)===> Epoch[707/1000]): Loss: 0.04487152651810656 Acc: 26524
(train)===> Epoch[708/1000]): Loss: 0.04710855740266285 Acc: 26495
(train)===> Epoch[709/1000]): Loss: 0.0454963828418227 Acc: 26498
(train)===> Epoch[710/1000]): Loss: 0.04722251963741953 Acc: 26497
(train)===> Epoch[711/1000]): Loss: 0.04561057190505918 Acc: 26495
(validation)===> Epoch[711/1000]): Acc: 0.9511217948717948
(train)===> Epoch[712/1000]): Loss: 0.04688690954679953 Acc: 26487
(train)===> Epoch[713/1000]): Loss: 0.04831769757941717 Acc: 26483
(train)===> Epoch[714/1000]): Loss: 0.046117928667732816 Acc: 26495
(train)===> Epoch[715/1000]): Loss: 0.048093649517244846 Acc: 26475
(train)===> Epoch[716/1000]): Loss: 0.04714716206671954 Acc: 26485
(train)===> Epoch[717/1000]): Loss: 0.047321305207071944 Acc: 26484
(train)===> Epoch[718/1000]): Loss: 0.04752944964382379 Acc: 26469
(train)===> Epoch[719/1000]): Loss: 0.04708158206128278 Acc: 26483
(train)===> Epoch[720/1000]): Loss: 0.04628648492728849 Acc: 26496
(train)===> Epoch[721/1000]): Loss: 0.047235106661110596 Acc: 26497
(validation)===> Epoch[721/1000]): Acc: 0.9551282051282052
(train)===> Epoch[722/1000]): Loss: 0.045826945635279934 Acc: 26501
(train)===> Epoch[723/1000]): Loss: 0.04940613556151096 Acc: 26477
(train)===> Epoch[724/1000]): Loss: 0.0458796473641409 Acc: 26488
(train)===> Epoch[725/1000]): Loss: 0.04900910761295831 Acc: 26483
(train)===> Epoch[726/1000]): Loss: 0.048927972039026435 Acc: 26455
(train)===> Epoch[727/1000]): Loss: 0.0475598243181317 Acc: 26500
(train)===> Epoch[728/1000]): Loss: 0.04656777392703409 Acc: 26517
(train)===> Epoch[729/1000]): Loss: 0.047930200710326366 Acc: 26495
(train)===> Epoch[730/1000]): Loss: 0.05052357156331831 Acc: 26483
(train)===> Epoch[731/1000]): Loss: 0.049555064739234704 Acc: 26473
(validation)===> Epoch[731/1000]): Acc: 0.9583333333333334
(train)===> Epoch[732/1000]): Loss: 0.04624339900280383 Acc: 26501
(train)===> Epoch[733/1000]): Loss: 0.04885175348715216 Acc: 26449
(train)===> Epoch[734/1000]): Loss: 0.046308231690728216 Acc: 26504
(train)===> Epoch[735/1000]): Loss: 0.05077423806238094 Acc: 26442
(train)===> Epoch[736/1000]): Loss: 0.04680678300170182 Acc: 26492
(train)===> Epoch[737/1000]): Loss: 0.049023855264650376 Acc: 26481
(train)===> Epoch[738/1000]): Loss: 0.04594849641744554 Acc: 26487
(train)===> Epoch[739/1000]): Loss: 0.04820289291140586 Acc: 26471
(train)===> Epoch[740/1000]): Loss: 0.04800962331271211 Acc: 26479
(train)===> Epoch[741/1000]): Loss: 0.04990906955512799 Acc: 26438
(validation)===> Epoch[741/1000]): Acc: 0.953926282051282
(train)===> Epoch[742/1000]): Loss: 0.046115121029366005 Acc: 26491
(train)===> Epoch[743/1000]): Loss: 0.04706266333654329 Acc: 26478
(train)===> Epoch[744/1000]): Loss: 0.04738494011434129 Acc: 26459
(train)===> Epoch[745/1000]): Loss: 0.045451471704277345 Acc: 26507
(train)===> Epoch[746/1000]): Loss: 0.046620518330267806 Acc: 26480
(train)===> Epoch[747/1000]): Loss: 0.04567344239282457 Acc: 26510
(train)===> Epoch[748/1000]): Loss: 0.04381184052176011 Acc: 26511
(train)===> Epoch[749/1000]): Loss: 0.04762273633104893 Acc: 26475
(train)===> Epoch[750/1000]): Loss: 0.045257729504173345 Acc: 26510
(train)===> Epoch[751/1000]): Loss: 0.046893633559186944 Acc: 26488
(validation)===> Epoch[751/1000]): Acc: 0.9547275641025641
(train)===> Epoch[752/1000]): Loss: 0.047433347075142344 Acc: 26492
(train)===> Epoch[753/1000]): Loss: 0.04399604964426179 Acc: 26516
(train)===> Epoch[754/1000]): Loss: 0.04880770806620239 Acc: 26471
(train)===> Epoch[755/1000]): Loss: 0.04736144543955032 Acc: 26469
(train)===> Epoch[756/1000]): Loss: 0.04842506586618263 Acc: 26468
(train)===> Epoch[757/1000]): Loss: 0.04815186732647734 Acc: 26467
(train)===> Epoch[758/1000]): Loss: 0.045818061259245556 Acc: 26505
(train)===> Epoch[759/1000]): Loss: 0.04602766822970467 Acc: 26504
(train)===> Epoch[760/1000]): Loss: 0.04467476926956356 Acc: 26526
(train)===> Epoch[761/1000]): Loss: 0.04536043725533946 Acc: 26499
(validation)===> Epoch[761/1000]): Acc: 0.953125
(train)===> Epoch[762/1000]): Loss: 0.04946242351551713 Acc: 26466
(train)===> Epoch[763/1000]): Loss: 0.049085163063371885 Acc: 26449
(train)===> Epoch[764/1000]): Loss: 0.04550337913941653 Acc: 26500
(train)===> Epoch[765/1000]): Loss: 0.0432333910794632 Acc: 26524
(train)===> Epoch[766/1000]): Loss: 0.045295233520261075 Acc: 26503
(train)===> Epoch[767/1000]): Loss: 0.04560506750825098 Acc: 26495
(train)===> Epoch[768/1000]): Loss: 0.046170329235963155 Acc: 26496
(train)===> Epoch[769/1000]): Loss: 0.046470212020121505 Acc: 26499
(train)===> Epoch[770/1000]): Loss: 0.04553671864927645 Acc: 26490
(train)===> Epoch[771/1000]): Loss: 0.04472759139288278 Acc: 26525
(validation)===> Epoch[771/1000]): Acc: 0.9551282051282052
(train)===> Epoch[772/1000]): Loss: 0.041523320414568354 Acc: 26549
(train)===> Epoch[773/1000]): Loss: 0.04498329063581032 Acc: 26513
(train)===> Epoch[774/1000]): Loss: 0.04521072757841838 Acc: 26502
(train)===> Epoch[775/1000]): Loss: 0.04730441323713776 Acc: 26459
(train)===> Epoch[776/1000]): Loss: 0.04620287134013449 Acc: 26487
(train)===> Epoch[777/1000]): Loss: 0.04773375197012869 Acc: 26488
(train)===> Epoch[778/1000]): Loss: 0.04768544328210965 Acc: 26458
(train)===> Epoch[779/1000]): Loss: 0.04502878313432858 Acc: 26497
(train)===> Epoch[780/1000]): Loss: 0.04746921839371694 Acc: 26460
(train)===> Epoch[781/1000]): Loss: 0.04792567204148674 Acc: 26486
(validation)===> Epoch[781/1000]): Acc: 0.9543269230769231
(train)===> Epoch[782/1000]): Loss: 0.045450554030224015 Acc: 26505
(train)===> Epoch[783/1000]): Loss: 0.04552304888400748 Acc: 26503
(train)===> Epoch[784/1000]): Loss: 0.047083576371331384 Acc: 26502
(train)===> Epoch[785/1000]): Loss: 0.04329926566930926 Acc: 26519
(train)===> Epoch[786/1000]): Loss: 0.04470621709238442 Acc: 26487
(train)===> Epoch[787/1000]): Loss: 0.042803644999306494 Acc: 26531
(train)===> Epoch[788/1000]): Loss: 0.05014287155329503 Acc: 26453
(train)===> Epoch[789/1000]): Loss: 0.04642598256148011 Acc: 26480
(train)===> Epoch[790/1000]): Loss: 0.04524248259445103 Acc: 26522
(train)===> Epoch[791/1000]): Loss: 0.044342464193891984 Acc: 26504
(validation)===> Epoch[791/1000]): Acc: 0.9535256410256411
(train)===> Epoch[792/1000]): Loss: 0.04471533529398495 Acc: 26530
(train)===> Epoch[793/1000]): Loss: 0.047133265167691556 Acc: 26485
(train)===> Epoch[794/1000]): Loss: 0.04550816293036 Acc: 26486
(train)===> Epoch[795/1000]): Loss: 0.04606925369729236 Acc: 26489
(train)===> Epoch[796/1000]): Loss: 0.044197424847218954 Acc: 26513
(train)===> Epoch[797/1000]): Loss: 0.04265048898670227 Acc: 26511
(train)===> Epoch[798/1000]): Loss: 0.04584566112098918 Acc: 26495
(train)===> Epoch[799/1000]): Loss: 0.045271294246230845 Acc: 26498
(train)===> Epoch[800/1000]): Loss: 0.04672509777213661 Acc: 26509
(train)===> Epoch[801/1000]): Loss: 0.0465596768824768 Acc: 26489
(validation)===> Epoch[801/1000]): Acc: 0.9583333333333334
(train)===> Epoch[802/1000]): Loss: 0.0450255917025743 Acc: 26514
(train)===> Epoch[803/1000]): Loss: 0.04466318257342175 Acc: 26517
(train)===> Epoch[804/1000]): Loss: 0.04475350876896246 Acc: 26514
(train)===> Epoch[805/1000]): Loss: 0.0428848149190765 Acc: 26523
(train)===> Epoch[806/1000]): Loss: 0.045339640697260826 Acc: 26506
(train)===> Epoch[807/1000]): Loss: 0.04622101564250109 Acc: 26495
(train)===> Epoch[808/1000]): Loss: 0.04408747626683119 Acc: 26515
(train)===> Epoch[809/1000]): Loss: 0.04383313536202654 Acc: 26523
(train)===> Epoch[810/1000]): Loss: 0.04433955099696914 Acc: 26521
(train)===> Epoch[811/1000]): Loss: 0.042306027166664845 Acc: 26533
(validation)===> Epoch[811/1000]): Acc: 0.9551282051282052
(train)===> Epoch[812/1000]): Loss: 0.047485192896988486 Acc: 26481
(train)===> Epoch[813/1000]): Loss: 0.04550349674101325 Acc: 26491
(train)===> Epoch[814/1000]): Loss: 0.04271637223165428 Acc: 26518
(train)===> Epoch[815/1000]): Loss: 0.043452741221785794 Acc: 26531
(train)===> Epoch[816/1000]): Loss: 0.04616370607463911 Acc: 26490
(train)===> Epoch[817/1000]): Loss: 0.044968369326470164 Acc: 26509
(train)===> Epoch[818/1000]): Loss: 0.04033705262072398 Acc: 26523
(train)===> Epoch[819/1000]): Loss: 0.04382541378121601 Acc: 26488
(train)===> Epoch[820/1000]): Loss: 0.043082625070927465 Acc: 26512
(train)===> Epoch[821/1000]): Loss: 0.04526603029213507 Acc: 26490
(validation)===> Epoch[821/1000]): Acc: 0.9555288461538461
(train)===> Epoch[822/1000]): Loss: 0.043562758315217415 Acc: 26521
(train)===> Epoch[823/1000]): Loss: 0.045536000733407564 Acc: 26491
(train)===> Epoch[824/1000]): Loss: 0.04464048559383671 Acc: 26490
(train)===> Epoch[825/1000]): Loss: 0.04387644811526756 Acc: 26523
(train)===> Epoch[826/1000]): Loss: 0.04300472217738056 Acc: 26519
(train)===> Epoch[827/1000]): Loss: 0.04523028936369827 Acc: 26489
(train)===> Epoch[828/1000]): Loss: 0.04289628780997777 Acc: 26531
(train)===> Epoch[829/1000]): Loss: 0.04290167549531021 Acc: 26512
(train)===> Epoch[830/1000]): Loss: 0.04461530171724087 Acc: 26512
(train)===> Epoch[831/1000]): Loss: 0.04407146996918026 Acc: 26515
(validation)===> Epoch[831/1000]): Acc: 0.9575320512820513
(train)===> Epoch[832/1000]): Loss: 0.04574476544122539 Acc: 26508
(train)===> Epoch[833/1000]): Loss: 0.047259612867250236 Acc: 26489
(train)===> Epoch[834/1000]): Loss: 0.04349943908814103 Acc: 26519
(train)===> Epoch[835/1000]): Loss: 0.045766670187999355 Acc: 26498
(train)===> Epoch[836/1000]): Loss: 0.04266008812930847 Acc: 26517
(train)===> Epoch[837/1000]): Loss: 0.04330612622995613 Acc: 26513
(train)===> Epoch[838/1000]): Loss: 0.04179590527242547 Acc: 26533
(train)===> Epoch[839/1000]): Loss: 0.043466845947326624 Acc: 26505
(train)===> Epoch[840/1000]): Loss: 0.04407400546226021 Acc: 26527
(train)===> Epoch[841/1000]): Loss: 0.043320868549218065 Acc: 26509
(validation)===> Epoch[841/1000]): Acc: 0.9543269230769231
(train)===> Epoch[842/1000]): Loss: 0.042782912410755866 Acc: 26524
(train)===> Epoch[843/1000]): Loss: 0.041810265931382616 Acc: 26538
(train)===> Epoch[844/1000]): Loss: 0.042735842317055225 Acc: 26529
(train)===> Epoch[845/1000]): Loss: 0.044380164505015716 Acc: 26496
(train)===> Epoch[846/1000]): Loss: 0.044084683357629544 Acc: 26524
(train)===> Epoch[847/1000]): Loss: 0.04229412798331763 Acc: 26523
(train)===> Epoch[848/1000]): Loss: 0.04359280881682093 Acc: 26515
(train)===> Epoch[849/1000]): Loss: 0.04376998608721749 Acc: 26522
(train)===> Epoch[850/1000]): Loss: 0.04424097242703189 Acc: 26508
(train)===> Epoch[851/1000]): Loss: 0.04328954062643604 Acc: 26527
(validation)===> Epoch[851/1000]): Acc: 0.9535256410256411
(train)===> Epoch[852/1000]): Loss: 0.04295438053440345 Acc: 26533
(train)===> Epoch[853/1000]): Loss: 0.04449570658970668 Acc: 26518
(train)===> Epoch[854/1000]): Loss: 0.04249955892160252 Acc: 26517
(train)===> Epoch[855/1000]): Loss: 0.04331211305379368 Acc: 26525
(train)===> Epoch[856/1000]): Loss: 0.045080913069288533 Acc: 26497
(train)===> Epoch[857/1000]): Loss: 0.04408704547373017 Acc: 26524
(train)===> Epoch[858/1000]): Loss: 0.04405423444795321 Acc: 26524
(train)===> Epoch[859/1000]): Loss: 0.04201291388812127 Acc: 26523
(train)===> Epoch[860/1000]): Loss: 0.04433646812291722 Acc: 26516
(train)===> Epoch[861/1000]): Loss: 0.04655480464934783 Acc: 26509
(validation)===> Epoch[861/1000]): Acc: 0.9583333333333334
(train)===> Epoch[862/1000]): Loss: 0.04244959313503187 Acc: 26513
(train)===> Epoch[863/1000]): Loss: 0.04145982776958758 Acc: 26534
(train)===> Epoch[864/1000]): Loss: 0.0419538979791326 Acc: 26525
(train)===> Epoch[865/1000]): Loss: 0.04242200202877126 Acc: 26524
(train)===> Epoch[866/1000]): Loss: 0.04199088805060915 Acc: 26519
(train)===> Epoch[867/1000]): Loss: 0.043312097024703476 Acc: 26532
(train)===> Epoch[868/1000]): Loss: 0.04042580032957863 Acc: 26546
(train)===> Epoch[869/1000]): Loss: 0.04462560293134169 Acc: 26507
(train)===> Epoch[870/1000]): Loss: 0.04255343784662211 Acc: 26536
(train)===> Epoch[871/1000]): Loss: 0.040503126225653246 Acc: 26549
(validation)===> Epoch[871/1000]): Acc: 0.953926282051282
(train)===> Epoch[872/1000]): Loss: 0.04505282325721009 Acc: 26514
(train)===> Epoch[873/1000]): Loss: 0.04397755231975956 Acc: 26515
(train)===> Epoch[874/1000]): Loss: 0.04266204779736495 Acc: 26527
(train)===> Epoch[875/1000]): Loss: 0.041401411584775345 Acc: 26546
(train)===> Epoch[876/1000]): Loss: 0.04318242436888767 Acc: 26515
(train)===> Epoch[877/1000]): Loss: 0.04400986945367199 Acc: 26514
(train)===> Epoch[878/1000]): Loss: 0.044572418933898024 Acc: 26516
(train)===> Epoch[879/1000]): Loss: 0.04336203246780016 Acc: 26523
(train)===> Epoch[880/1000]): Loss: 0.045225898639548984 Acc: 26489
(train)===> Epoch[881/1000]): Loss: 0.04334070732470852 Acc: 26517
(validation)===> Epoch[881/1000]): Acc: 0.9583333333333334
(train)===> Epoch[882/1000]): Loss: 0.04475755319817793 Acc: 26475
(train)===> Epoch[883/1000]): Loss: 0.04206703021356973 Acc: 26526
(train)===> Epoch[884/1000]): Loss: 0.04547338278476378 Acc: 26501
(train)===> Epoch[885/1000]): Loss: 0.04198845518109191 Acc: 26530
(train)===> Epoch[886/1000]): Loss: 0.04289824512041663 Acc: 26527
(train)===> Epoch[887/1000]): Loss: 0.043564173471759976 Acc: 26503
(train)===> Epoch[888/1000]): Loss: 0.04273240408813692 Acc: 26536
(train)===> Epoch[889/1000]): Loss: 0.04233922205219434 Acc: 26531
(train)===> Epoch[890/1000]): Loss: 0.04168227612043151 Acc: 26514
(train)===> Epoch[891/1000]): Loss: 0.041803302755468695 Acc: 26554
(validation)===> Epoch[891/1000]): Acc: 0.9563301282051282
(train)===> Epoch[892/1000]): Loss: 0.04421876229079232 Acc: 26495
(train)===> Epoch[893/1000]): Loss: 0.04413875464555716 Acc: 26509
(train)===> Epoch[894/1000]): Loss: 0.04081403880408848 Acc: 26537
(train)===> Epoch[895/1000]): Loss: 0.04436667345966392 Acc: 26508
(train)===> Epoch[896/1000]): Loss: 0.04199459920653898 Acc: 26550
(train)===> Epoch[897/1000]): Loss: 0.042571676365208255 Acc: 26525
(train)===> Epoch[898/1000]): Loss: 0.04397953655034294 Acc: 26514
(train)===> Epoch[899/1000]): Loss: 0.04188448448904355 Acc: 26521
(train)===> Epoch[900/1000]): Loss: 0.04335277231693305 Acc: 26538
(train)===> Epoch[901/1000]): Loss: 0.04125591113249778 Acc: 26541
(validation)===> Epoch[901/1000]): Acc: 0.9555288461538461
(train)===> Epoch[902/1000]): Loss: 0.04291864087741 Acc: 26531
(train)===> Epoch[903/1000]): Loss: 0.043304295636903786 Acc: 26494
(train)===> Epoch[904/1000]): Loss: 0.043915759587346344 Acc: 26520
(train)===> Epoch[905/1000]): Loss: 0.04161070744316765 Acc: 26535
(train)===> Epoch[906/1000]): Loss: 0.04137329572608202 Acc: 26551
(train)===> Epoch[907/1000]): Loss: 0.042288341740314435 Acc: 26530
(train)===> Epoch[908/1000]): Loss: 0.040584665214622985 Acc: 26545
(train)===> Epoch[909/1000]): Loss: 0.0425774109889388 Acc: 26532
(train)===> Epoch[910/1000]): Loss: 0.04241633296539378 Acc: 26526
(train)===> Epoch[911/1000]): Loss: 0.041290959124862595 Acc: 26545
(validation)===> Epoch[911/1000]): Acc: 0.9495192307692307
(train)===> Epoch[912/1000]): Loss: 0.044559280186473496 Acc: 26498
(train)===> Epoch[913/1000]): Loss: 0.04101451184996569 Acc: 26511
(train)===> Epoch[914/1000]): Loss: 0.041719602871655256 Acc: 26545
(train)===> Epoch[915/1000]): Loss: 0.03984196405280425 Acc: 26555
(train)===> Epoch[916/1000]): Loss: 0.040111846347492076 Acc: 26557
(train)===> Epoch[917/1000]): Loss: 0.0390573677760626 Acc: 26569
(train)===> Epoch[918/1000]): Loss: 0.041760983185581614 Acc: 26529
(train)===> Epoch[919/1000]): Loss: 0.042549259858891686 Acc: 26531
(train)===> Epoch[920/1000]): Loss: 0.04349677482022037 Acc: 26506
(train)===> Epoch[921/1000]): Loss: 0.039397325161003874 Acc: 26577
(validation)===> Epoch[921/1000]): Acc: 0.9547275641025641
(train)===> Epoch[922/1000]): Loss: 0.04159581538836189 Acc: 26538
(train)===> Epoch[923/1000]): Loss: 0.04211770644524272 Acc: 26535
(train)===> Epoch[924/1000]): Loss: 0.04150906052648349 Acc: 26550
(train)===> Epoch[925/1000]): Loss: 0.041341299310021284 Acc: 26544
(train)===> Epoch[926/1000]): Loss: 0.04267933956945244 Acc: 26548
(train)===> Epoch[927/1000]): Loss: 0.04291730370005315 Acc: 26517
(train)===> Epoch[928/1000]): Loss: 0.041657002005093445 Acc: 26531
(train)===> Epoch[929/1000]): Loss: 0.04194531862893872 Acc: 26542
(train)===> Epoch[930/1000]): Loss: 0.04002239596543308 Acc: 26565
(train)===> Epoch[931/1000]): Loss: 0.04207639261939724 Acc: 26521
(validation)===> Epoch[931/1000]): Acc: 0.9611378205128205
(train)===> Epoch[932/1000]): Loss: 0.037885636974993274 Acc: 26578
(train)===> Epoch[933/1000]): Loss: 0.04189743710772493 Acc: 26514
(train)===> Epoch[934/1000]): Loss: 0.04044861136659136 Acc: 26553
(train)===> Epoch[935/1000]): Loss: 0.042414545227005905 Acc: 26532
(train)===> Epoch[936/1000]): Loss: 0.04190888761093664 Acc: 26530
(train)===> Epoch[937/1000]): Loss: 0.041982175338783255 Acc: 26528
(train)===> Epoch[938/1000]): Loss: 0.04034414694278399 Acc: 26543
(train)===> Epoch[939/1000]): Loss: 0.04236298748579613 Acc: 26532
(train)===> Epoch[940/1000]): Loss: 0.038457208232580295 Acc: 26592
(train)===> Epoch[941/1000]): Loss: 0.04118477903619506 Acc: 26540
(validation)===> Epoch[941/1000]): Acc: 0.9583333333333334
(train)===> Epoch[942/1000]): Loss: 0.04387729592851392 Acc: 26513
(train)===> Epoch[943/1000]): Loss: 0.04026914989319132 Acc: 26568
(train)===> Epoch[944/1000]): Loss: 0.04169050162943464 Acc: 26535
(train)===> Epoch[945/1000]): Loss: 0.042029975053484825 Acc: 26542
(train)===> Epoch[946/1000]): Loss: 0.04080751734191767 Acc: 26545
(train)===> Epoch[947/1000]): Loss: 0.04229397728326872 Acc: 26524
(train)===> Epoch[948/1000]): Loss: 0.043063374883285134 Acc: 26522
(train)===> Epoch[949/1000]): Loss: 0.04425542725132878 Acc: 26512
(train)===> Epoch[950/1000]): Loss: 0.04002051292520431 Acc: 26545
(train)===> Epoch[951/1000]): Loss: 0.04281347588748802 Acc: 26509
(validation)===> Epoch[951/1000]): Acc: 0.9515224358974359
(train)===> Epoch[952/1000]): Loss: 0.0384171683371129 Acc: 26562
(train)===> Epoch[953/1000]): Loss: 0.041799053634658453 Acc: 26541
(train)===> Epoch[954/1000]): Loss: 0.04013260522074199 Acc: 26563
(train)===> Epoch[955/1000]): Loss: 0.037364040213833966 Acc: 26577
(train)===> Epoch[956/1000]): Loss: 0.0423132292660851 Acc: 26514
(train)===> Epoch[957/1000]): Loss: 0.04128131098578507 Acc: 26542
(train)===> Epoch[958/1000]): Loss: 0.04098351551396794 Acc: 26552
(train)===> Epoch[959/1000]): Loss: 0.0418074425661631 Acc: 26512
(train)===> Epoch[960/1000]): Loss: 0.03970682788297377 Acc: 26563
(train)===> Epoch[961/1000]): Loss: 0.03858186723111361 Acc: 26597
(validation)===> Epoch[961/1000]): Acc: 0.953125
(train)===> Epoch[962/1000]): Loss: 0.04045551450040433 Acc: 26534
(train)===> Epoch[963/1000]): Loss: 0.042384307215437116 Acc: 26523
(train)===> Epoch[964/1000]): Loss: 0.04473638975596818 Acc: 26499
(train)===> Epoch[965/1000]): Loss: 0.0410917640158756 Acc: 26559
(train)===> Epoch[966/1000]): Loss: 0.03858919721594492 Acc: 26543
(train)===> Epoch[967/1000]): Loss: 0.04287584288147526 Acc: 26526
(train)===> Epoch[968/1000]): Loss: 0.040888898973873065 Acc: 26534
(train)===> Epoch[969/1000]): Loss: 0.03793095401488243 Acc: 26563
(train)===> Epoch[970/1000]): Loss: 0.04026140147546915 Acc: 26550
(train)===> Epoch[971/1000]): Loss: 0.03882244915309896 Acc: 26570
(validation)===> Epoch[971/1000]): Acc: 0.953125
(train)===> Epoch[972/1000]): Loss: 0.04210596085352395 Acc: 26547
(train)===> Epoch[973/1000]): Loss: 0.042279290644266165 Acc: 26525
(train)===> Epoch[974/1000]): Loss: 0.04121841578423591 Acc: 26531
(train)===> Epoch[975/1000]): Loss: 0.04174087354758506 Acc: 26529
(train)===> Epoch[976/1000]): Loss: 0.039111797761994936 Acc: 26565
(train)===> Epoch[977/1000]): Loss: 0.03814133465778961 Acc: 26559
(train)===> Epoch[978/1000]): Loss: 0.04234889259970039 Acc: 26533
(train)===> Epoch[979/1000]): Loss: 0.040540939023012604 Acc: 26555
(train)===> Epoch[980/1000]): Loss: 0.0400020981831321 Acc: 26550
(train)===> Epoch[981/1000]): Loss: 0.04084245058665863 Acc: 26533
(validation)===> Epoch[981/1000]): Acc: 0.9491185897435898
(train)===> Epoch[982/1000]): Loss: 0.040144203021688786 Acc: 26549
(train)===> Epoch[983/1000]): Loss: 0.03865172592602281 Acc: 26587
(train)===> Epoch[984/1000]): Loss: 0.0386687675092785 Acc: 26564
(train)===> Epoch[985/1000]): Loss: 0.041201477775774965 Acc: 26542
(train)===> Epoch[986/1000]): Loss: 0.041648929527763806 Acc: 26554
(train)===> Epoch[987/1000]): Loss: 0.0394560959044404 Acc: 26550
(train)===> Epoch[988/1000]): Loss: 0.04189593294765935 Acc: 26520
(train)===> Epoch[989/1000]): Loss: 0.041914273888500955 Acc: 26514
(train)===> Epoch[990/1000]): Loss: 0.03748502767359455 Acc: 26585
(train)===> Epoch[991/1000]): Loss: 0.04059571567635248 Acc: 26548
(validation)===> Epoch[991/1000]): Acc: 0.9479166666666666
(train)===> Epoch[992/1000]): Loss: 0.037001399003686014 Acc: 26598
(train)===> Epoch[993/1000]): Loss: 0.03920204179818272 Acc: 26551
(train)===> Epoch[994/1000]): Loss: 0.042395127316131626 Acc: 26529
(train)===> Epoch[995/1000]): Loss: 0.03935658374957238 Acc: 26560
(train)===> Epoch[996/1000]): Loss: 0.040302669562260064 Acc: 26540
(train)===> Epoch[997/1000]): Loss: 0.041147774827308206 Acc: 26538
(train)===> Epoch[998/1000]): Loss: 0.040429698699043386 Acc: 26542
(train)===> Epoch[999/1000]): Loss: 0.038975312958544464 Acc: 26542
(train)===> Epoch[1000/1000]): Loss: 0.039851502116632395 Acc: 26538
